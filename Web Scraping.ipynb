{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing team attributes, not teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usable Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell gathers URL ends that will be inputted into the subsequent cell in order to gather relevant data for EACH game that will be inputted into a Pandas DF object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years = range(2011, 2020)\n",
    "weeks = range(1,22)\n",
    "#years = [2019]\n",
    "#weeks = [1,2]\n",
    "game_link_ends = []\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get to the actual game pages where we can extract data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.pro-football-reference.com'\n",
    "url_list = []\n",
    "for game_link in game_link_ends:\n",
    "    url = ''.join([url2, game_link])\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2403 2403\n"
     ]
    }
   ],
   "source": [
    "#Sanity checks to make sure we get all the boxscore links & subsequent pages (267 games/year)\n",
    "#print(*url_list, sep='\\n')\n",
    "print(len(url_list), len(game_link_ends))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are actually on the pages where we can grab info for a model, let's grab it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_stat_dict(url):\n",
    "    '''\n",
    "    From Pro-Football-Reference link stub, request gamepage, parse with BeautifulSoup, and\n",
    "    collect \n",
    "        - game total (target) \n",
    "        - traditional stats (features)\n",
    "        - efficiency stats (features)\n",
    "    Return total & stats as a dictionary.\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    page = page.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    headers = ['total','tot_1st','tot_rush_att','tot_rush_yds','tot_rush_tds',\n",
    "               'tot_comp','tot_att','tot_pass_yds','total_pass_tds','total_int',\n",
    "               'tot_sacks','tot_sack_yds','tot_net_pass_yds','total_tot_yds',\n",
    "               'tot_fum','tot_fum_l','total_to','tot_pen','tot_pen_yds',\n",
    "               'tot_third_conv','tot_thirds','tot_third_per',\n",
    "               'tot_fourth_conv','tot_fourths','tot_fourth_per',\n",
    "               'margin','tot_off_epa','tot_pass_epa','tot_rush_epa','tot_to_epa','tot_spec_epa']\n",
    "\n",
    "#scrape totals from scorebox at top of page\n",
    "    team_scores = []\n",
    "    table = soup.find('table', class_=\"linescore nohover stats_table no_freeze\")\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        #cols = [ele.text.strip() for ele in cols]\n",
    "        team_scores.append([ele for ele in cols[-1] if ele]) # Get rid of empty values\n",
    "    total = sum([int(scores) for teams in team_scores for scores in teams]) #flatten list to be able to add\n",
    "\n",
    "#scrape team stats box for traditional metrics\n",
    "    data1 = []\n",
    "    table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "    table_body1 = table1.find('tbody')\n",
    "\n",
    "    rows1 = table_body1.find_all('tr')\n",
    "    for row in rows1:\n",
    "        cols = row.find_all('td')\n",
    "        #cols = [ele.text.strip() for ele in cols]\n",
    "        data1.append([ele.text for ele in cols if ele]) # Get rid of empty values\n",
    "#process traditional stats table\n",
    "#total first downs\n",
    "    total_first_downs = sum(int(item) for item in data1[0])\n",
    "#separate rush stats & make appropriate transformations\n",
    "    rush_stats = [item.split('-') for item in data1[1]]\n",
    "    total_rush_att = int(rush_stats[0][0]) + int(rush_stats[1][0])\n",
    "    total_rush_yds = int(rush_stats[0][1]) + int(rush_stats[1][1])\n",
    "    total_rush_tds = int(rush_stats[0][2]) + int(rush_stats[1][2])\n",
    "#separate pass stats & make appropriate transformations\n",
    "    pass_stats = [item.split('-') for item in data1[2]]\n",
    "    total_comp = int(pass_stats[0][0]) + int(pass_stats[1][0])\n",
    "    total_att = int(pass_stats[0][1]) + int(pass_stats[1][1])\n",
    "    total_pass_yds = int(pass_stats[0][2]) + int(pass_stats[1][2])\n",
    "    total_pass_tds = int(pass_stats[0][3]) + int(pass_stats[1][3])\n",
    "    total_int = int(pass_stats[0][4]) + int(pass_stats[1][4])\n",
    "#separate sack stats & make appropriate transformations\n",
    "    sack_stats = [item.split('-') for item in data1[3]]\n",
    "    total_sacks = int(sack_stats[0][0]) + int(sack_stats[1][0])\n",
    "    total_sack_yds = int(sack_stats[0][1]) + int(sack_stats[1][1])\n",
    "#net pass yards & total yards (stats don't require splits)\n",
    "    total_net_pass_yds = int(data1[4][0]) + int(data1[4][1])\n",
    "    total_tot_yds = int(data1[5][0]) + int(data1[5][1])\n",
    "#separate fumbles & make appropriate transformations\n",
    "    fum_stats = [item.split('-') for item in data1[6]]\n",
    "    total_fum = int(fum_stats[0][0]) + int(fum_stats[1][0])\n",
    "    total_fum_l = int(fum_stats[0][1]) + int(fum_stats[1][1])\n",
    "#turnover stats (doesn't require split)\n",
    "    total_to = int(data1[7][0]) + int(data1[7][1])\n",
    "#separate penalty stats & make appropriate transformations\n",
    "    pen_stats = [item.split('-') for item in data1[8]]\n",
    "    total_pen = int(pen_stats[0][0]) + int(pen_stats[1][0])\n",
    "    total_pen_yds = int(pen_stats[0][1]) + int(pen_stats[1][1])\n",
    "#separate 3rd down stats & make appropriate transformations\n",
    "    third_dn_stats = [item.split('-') for item in data1[9]]\n",
    "    total_third_conv = int(third_dn_stats[0][0]) + int(third_dn_stats[1][0])\n",
    "    total_thirds = int(third_dn_stats[0][1]) + int(third_dn_stats[1][1])\n",
    "    total_third_per = round(100*total_third_conv/total_thirds,2)\n",
    "#separate 4th down stats & make appropriate transformations\n",
    "    fourth_dn_stats = [item.split('-') for item in data1[10]]\n",
    "    total_fourth_conv = int(fourth_dn_stats[0][0]) + int(fourth_dn_stats[1][0])\n",
    "    total_fourths = int(fourth_dn_stats[0][1]) + int(fourth_dn_stats[1][1])\n",
    "    if total_fourths != 0:\n",
    "        total_fourth_per = round(100*total_fourth_conv/total_fourths,2)\n",
    "    else:\n",
    "        total_fourth_per = None\n",
    "\n",
    "#scrape team stats box for efficiency metrics\n",
    "    data2 = []\n",
    "    table2 = soup.find('table', id='expected_points')\n",
    "    table_body2 = table2.find('tbody')\n",
    "\n",
    "    rows2 = table_body2.find_all('tr')\n",
    "    for row in rows2:\n",
    "        cols = row.find_all('td')\n",
    "        data2.append([ele.text for ele in cols if ele]) # Get rid of empty values\n",
    "#grab relevant OFFESNIVE values & make appropriate transformations (defensive numbers are flipped sign)\n",
    "    scoring_margin = int(abs(float(data2[0][0])))\n",
    "    total_off_epa = round(float(data2[0][1]) + float(data2[1][1]),2)\n",
    "    total_pass_epa = round(float(data2[0][2]) + float(data2[1][2]),2)\n",
    "    total_rush_epa = round(float(data2[0][3]) + float(data2[1][3]),2)\n",
    "    total_to_epa = round(float(data2[0][4]) + float(data2[1][4]),2)\n",
    "    total_spec_epa = abs(float(data2[0][9]))\n",
    "\n",
    "#make a dictionary of all the stats pulled from the gamepage\n",
    "    game_dict = dict(zip(headers,[total,total_first_downs,total_rush_att,total_rush_yds,total_rush_tds,\n",
    "                                  total_comp,total_att,total_pass_yds,total_pass_tds,total_int,\n",
    "                                  total_sacks,total_sack_yds,total_net_pass_yds,total_tot_yds,\n",
    "                                  total_fum,total_fum_l,total_to,total_pen,total_pen_yds,\n",
    "                                  total_third_conv,total_thirds,total_third_per,\n",
    "                                  total_fourth_conv,total_fourths,total_fourth_per,\n",
    "                                  scoring_margin,total_off_epa,total_pass_epa,total_rush_epa,\n",
    "                                  total_to_epa,total_spec_epa]))\n",
    "    return game_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    game_list.append(game_stat_dict(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>tot_1st</th>\n",
       "      <th>tot_rush_att</th>\n",
       "      <th>tot_rush_yds</th>\n",
       "      <th>tot_rush_tds</th>\n",
       "      <th>tot_comp</th>\n",
       "      <th>tot_att</th>\n",
       "      <th>tot_pass_yds</th>\n",
       "      <th>total_pass_tds</th>\n",
       "      <th>total_int</th>\n",
       "      <th>...</th>\n",
       "      <th>tot_third_per</th>\n",
       "      <th>tot_fourth_conv</th>\n",
       "      <th>tot_fourths</th>\n",
       "      <th>tot_fourth_per</th>\n",
       "      <th>margin</th>\n",
       "      <th>tot_off_epa</th>\n",
       "      <th>tot_pass_epa</th>\n",
       "      <th>tot_rush_epa</th>\n",
       "      <th>tot_to_epa</th>\n",
       "      <th>tot_spec_epa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>84</td>\n",
       "      <td>731</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>43.00</td>\n",
       "      <td>38.99</td>\n",
       "      <td>4.54</td>\n",
       "      <td>-3.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>396</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18</td>\n",
       "      <td>8.39</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7.93</td>\n",
       "      <td>-15.10</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>70</td>\n",
       "      <td>504</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-29.55</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>438</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>44.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3.30</td>\n",
       "      <td>8.45</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>417</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>-11.81</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>-24.37</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total  tot_1st  tot_rush_att  tot_rush_yds  tot_rush_tds  tot_comp  \\\n",
       "0     76       54            48           184             2        59   \n",
       "1     44       48            58           390             2        32   \n",
       "2     42       37            47           236             1        39   \n",
       "3     30       33            60           206             1        38   \n",
       "4     41       41            57           231             2        33   \n",
       "\n",
       "   tot_att  tot_pass_yds  total_pass_tds  total_int  ...  tot_third_per  \\\n",
       "0       84           731               6          0  ...          65.38   \n",
       "1       67           396               2          0  ...          40.00   \n",
       "2       70           504               4          3  ...          40.00   \n",
       "3       58           438               2          1  ...          44.83   \n",
       "4       55           417               2          2  ...          30.00   \n",
       "\n",
       "   tot_fourth_conv  tot_fourths  tot_fourth_per  margin  tot_off_epa  \\\n",
       "0                0            1             0.0       8        43.00   \n",
       "1                2            4            50.0      18         8.39   \n",
       "2                0            2             0.0      27       -12.06   \n",
       "3                0            0             NaN       2         3.30   \n",
       "4                0            1             0.0      27       -11.81   \n",
       "\n",
       "   tot_pass_epa  tot_rush_epa  tot_to_epa  tot_spec_epa  \n",
       "0         38.99          4.54       -3.32          1.53  \n",
       "1          3.99          7.93      -15.10          0.21  \n",
       "2        -10.10         -0.69      -29.55          3.57  \n",
       "3          8.45         -5.50       -5.12          2.37  \n",
       "4         -1.75         -8.81      -24.37          8.14  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df = pd.DataFrame(game_list) #convert list of dicts to DF\n",
    "game_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2403, 31)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('game_df.pickle', 'wb') as to_write:\n",
    "    pickle.dump(game_df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check that all games went through the function\n",
    "print(len(game_list), len(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.pro-football-reference.com/boxscores/201909160nyj.htm'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check link\n",
    "#url_list[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 26,\n",
       " 'tot_1st': 29,\n",
       " 'tot_rush_att': 45,\n",
       " 'tot_rush_yds': 163,\n",
       " 'tot_rush_tds': 1,\n",
       " 'tot_comp': 42,\n",
       " 'tot_att': 66,\n",
       " 'tot_pass_yds': 526,\n",
       " 'total_pass_tds': 1,\n",
       " 'total_int': 1,\n",
       " 'tot_sacks': 7,\n",
       " 'tot_sack_yds': 52,\n",
       " 'tot_net_pass_yds': 474,\n",
       " 'total_tot_yds': 637,\n",
       " 'tot_fum': 1,\n",
       " 'tot_fum_l': 1,\n",
       " 'total_to': 2,\n",
       " 'tot_pen': 21,\n",
       " 'tot_pen_yds': 174,\n",
       " 'tot_third_conv': 6,\n",
       " 'tot_thirds': 27,\n",
       " 'tot_third_per': 22.22,\n",
       " 'tot_fourth_conv': 0,\n",
       " 'tot_fourths': 2,\n",
       " 'tot_fourth_per': 0.0,\n",
       " 'margin': 20,\n",
       " 'tot_off_epa': -9.47,\n",
       " 'tot_pass_epa': -0.95,\n",
       " 'tot_rush_epa': -6.29,\n",
       " 'tot_to_epa': -7.22,\n",
       " 'tot_spec_epa': 0.9}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check stats\n",
    "#game_list[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check on dictionary key-value pairs\n",
    "headers = ['total','tot_1st','tot_rush_att','tot_rush_yds','tot_rush_tds',\n",
    "               'tot_comp','tot_att','tot_pass_yds','total_pass_tds','total_int',\n",
    "               'tot_sacks','tot_sack_yds','tot_net_pass_yds','total_tot_yds',\n",
    "               'tot_fum','tot_fum_l','total_to','tot_pen','tot_pen_yds',\n",
    "               'tot_third_conv','tot_thirds','tot_third_per',\n",
    "               'tot_fourth_conv','tot_fourths','tot_fourth_per',\n",
    "               'margin','tot_off_epa','tot_pass_epa','tot_rush_epa','tot_to_epa','tot_spec_epa']\n",
    "stats = [total,total_first_downs,total_rush_att,total_rush_yds,total_rush_tds,\n",
    "         total_comp,total_att,total_pass_yds,total_pass_tds,total_int,\n",
    "         total_sacks,total_sack_yds,total_net_pass_yds,total_tot_yds,\n",
    "         total_fum,total_fum_l,total_to,total_pen,total_pen_yds,\n",
    "         total_third_conv,total_thirds,total_third_per,\n",
    "         total_fourth_conv,total_fourths,total_fourth_per,\n",
    "         scoring_margin,total_off_epa,total_pass_epa,total_rush_epa,total_to_epa,total_spec_epa]\n",
    "\n",
    "#len(headers) - len(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workable Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.pro-football-reference.com/boxscores/201909050chi.htm'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with first game to get a sense of basic structure; REMOVE COMMENTS\n",
    "response = requests.get(url_list[0])\n",
    "page = response.text\n",
    "page = page.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape totals from scorebox at top of page\n",
    "data = []\n",
    "table = soup.find('table', class_=\"linescore nohover stats_table no_freeze\")\n",
    "table_body = table.find('tbody')\n",
    "\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    #cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols[-1] if ele]) # Get rid of empty values\n",
    "\n",
    "total = sum([int(item) for sublist in data for item in sublist])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Traditional Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['13', '16'],\n",
       " ['22-47-0', '15-46-0'],\n",
       " ['18-30-203-1-0', '26-45-228-0-1'],\n",
       " ['5-37', '5-20'],\n",
       " ['166', '208'],\n",
       " ['213', '254'],\n",
       " ['1-0', '0-0'],\n",
       " ['0', '1'],\n",
       " ['10-71', '10-107'],\n",
       " ['2-12', '3-15'],\n",
       " ['0-0', '0-2'],\n",
       " ['31:03', '28:57']]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape team stats box for traditional metrics\n",
    "data1 = []\n",
    "table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "table_body1 = table1.find('tbody')\n",
    "\n",
    "rows1 = table_body1.find_all('tr')\n",
    "for row in rows1:\n",
    "    cols = row.find_all('td')\n",
    "    #cols = [ele.text.strip() for ele in cols]\n",
    "    data1.append([ele.text for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Traditional Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "#total first downs\n",
    "total_first_downs = sum(int(item) for item in data1[0])\n",
    "print(total_first_downs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "93\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#separate rush stats and make appropriate transformations\n",
    "rush_stats = [item.split('-') for item in data1[1]]\n",
    "total_rush_att = int(rush_stats[0][0]) + int(rush_stats[1][0])\n",
    "print(total_rush_att)\n",
    "total_rush_yds = int(rush_stats[0][1]) + int(rush_stats[1][1])\n",
    "print(total_rush_yds)\n",
    "total_rush_tds = int(rush_stats[0][2]) + int(rush_stats[1][2])\n",
    "print(total_rush_tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "75\n",
      "431\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#separate pass stats and make appropriate transformations\n",
    "pass_stats = [item.split('-') for item in data1[2]]\n",
    "#print(pass_stats)\n",
    "total_comp = int(pass_stats[0][0]) + int(pass_stats[1][0])\n",
    "print(total_comp)\n",
    "total_att = int(pass_stats[0][1]) + int(pass_stats[1][1])\n",
    "print(total_att)\n",
    "total_pass_yds = int(pass_stats[0][2]) + int(pass_stats[1][2])\n",
    "print(total_pass_yds)\n",
    "total_pass_tds = int(pass_stats[0][3]) + int(pass_stats[1][3])\n",
    "print(total_pass_tds)\n",
    "total_int = int(pass_stats[0][4]) + int(pass_stats[1][4])\n",
    "print(total_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "#seperate sacks and make appropriate transformations\n",
    "sack_stats = [item.split('-') for item in data1[3]]\n",
    "#print(sack_stats)\n",
    "total_sacks = int(sack_stats[0][0]) + int(sack_stats[1][0])\n",
    "print(total_sacks)\n",
    "total_sack_yds = int(sack_stats[0][1]) + int(sack_stats[1][1])\n",
    "print(total_sack_yds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n",
      "467\n"
     ]
    }
   ],
   "source": [
    "#net pass yards & total yards (stats that don't require splits)\n",
    "total_net_pass_yds = int(data1[4][0]) + int(data1[4][1])\n",
    "print(total_net_pass_yds)\n",
    "total_tot_yds = int(data1[5][0]) + int(data1[5][1])\n",
    "print(total_tot_yds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '0'], ['0', '0']]\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#seperate fumbles and make appropriate transformations\n",
    "fum_stats = [item.split('-') for item in data1[6]]\n",
    "print(fum_stats)\n",
    "total_fum = int(fum_stats[0][0]) + int(fum_stats[1][0])\n",
    "print(total_fum)\n",
    "total_fum_l = int(fum_stats[0][1]) + int(fum_stats[1][1])\n",
    "print(total_fum_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#turnover stats (doesn't require split)\n",
    "total_to = int(data1[7][0]) + int(data1[7][1])\n",
    "print(total_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10', '71'], ['10', '107']]\n",
      "20\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "#seperate penalities & make appropriate transformations\n",
    "pen_stats = [item.split('-') for item in data1[8]]\n",
    "print(pen_stats)\n",
    "total_pen = int(pen_stats[0][0]) + int(pen_stats[1][0])\n",
    "print(total_pen)\n",
    "total_pen_yds = int(pen_stats[0][1]) + int(pen_stats[1][1])\n",
    "print(total_pen_yds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2', '12'], ['3', '15']]\n",
      "5\n",
      "27\n",
      "18.52\n"
     ]
    }
   ],
   "source": [
    "#seperate 3rd downs & make appropriate transformations\n",
    "third_dn_stats = [item.split('-') for item in data1[9]]\n",
    "print(third_dn_stats)\n",
    "total_third_conv = int(third_dn_stats[0][0]) + int(third_dn_stats[1][0])\n",
    "print(total_third_conv)\n",
    "total_thirds = int(third_dn_stats[0][1]) + int(third_dn_stats[1][1])\n",
    "print(total_thirds)\n",
    "total_third_per = round(100*total_third_conv/total_thirds,2)\n",
    "print(total_third_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0'], ['0', '2']]\n",
      "0\n",
      "2\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#seperate 4th downs & make appropriate transformations\n",
    "fourth_dn_stats = [item.split('-') for item in data1[10]]\n",
    "print(fourth_dn_stats)\n",
    "total_fourth_conv = int(fourth_dn_stats[0][0]) + int(fourth_dn_stats[1][0])\n",
    "print(total_fourth_conv)\n",
    "total_fourths = int(fourth_dn_stats[0][1]) + int(fourth_dn_stats[1][1])\n",
    "print(total_fourths)\n",
    "total_fourth_per = round(100*total_fourth_conv/total_fourths,2)\n",
    "print(total_fourth_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "total_fourth_conv = 0\n",
    "total_fourths = 0\n",
    "if total_fourths != 0:\n",
    "    total_fourth_per = round(100*total_fourth_conv/total_fourths,2)\n",
    "else:\n",
    "    total_fourth_per = None\n",
    "print(total_fourth_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Efficiency Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-7.00',\n",
       "  '-20.02',\n",
       "  '-14.69',\n",
       "  '-4.34',\n",
       "  '-3.36',\n",
       "  '9.57',\n",
       "  '-2.26',\n",
       "  '10.15',\n",
       "  '0.00',\n",
       "  '-2.01',\n",
       "  '-2.21',\n",
       "  '1.83',\n",
       "  '4.70',\n",
       "  '-6.31',\n",
       "  '-0.02'],\n",
       " ['7.00',\n",
       "  '-9.57',\n",
       "  '2.26',\n",
       "  '-10.15',\n",
       "  '0.00',\n",
       "  '20.02',\n",
       "  '14.69',\n",
       "  '4.34',\n",
       "  '3.36',\n",
       "  '2.01',\n",
       "  '-1.83',\n",
       "  '2.21',\n",
       "  '6.31',\n",
       "  '-4.70',\n",
       "  '0.02']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape team stats box for efficiency metrics\n",
    "data2 = []\n",
    "table2 = soup.find('table', id='expected_points')\n",
    "table_body2 = table2.find('tbody')\n",
    "\n",
    "rows2 = table_body2.find_all('tr')\n",
    "for row in rows2:\n",
    "    cols = row.find_all('td')\n",
    "    #cols = [ele.text.strip() for ele in cols]\n",
    "    data2.append([ele.text for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Efficiency Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "-29.59\n",
      "-12.43\n",
      "-14.49\n",
      "-3.36\n",
      "2.01\n"
     ]
    }
   ],
   "source": [
    "#grab relevant OFFESNIVE values & make appropriate transformations (defensive numbers are flipped sign)\n",
    "scoring_margin = int(abs(float(data2[0][0])))\n",
    "print(scoring_margin)\n",
    "total_off_epa = round(float(data2[0][1]) + float(data2[1][1]),2)\n",
    "print(total_off_epa)\n",
    "total_pass_epa = round(float(data2[0][2]) + float(data2[1][2]),2)\n",
    "print(total_pass_epa)\n",
    "total_rush_epa = round(float(data2[0][3]) + float(data2[1][3]),2)\n",
    "print(total_rush_epa)\n",
    "total_to_epa = round(float(data2[0][4]) + float(data2[1][4]),2)\n",
    "print(total_to_epa)\n",
    "total_spec_epa = abs(float(data2[0][9]))\n",
    "print(total_spec_epa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work Graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cirlce back for:\n",
    "- Play-by-play table to grab EPA's\n",
    "- Another source for other advanced stats (CPOE)\n",
    "- QB specific stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Play-By-Play table, doesn't seem to pull in BS since it has weird \"comment\" section above it...\n",
    "#will cirlce back if time permits\n",
    "#REDEFINE DUMMY VARIABLES!!\n",
    "data2 = []\n",
    "table2 = soup.find('table', class_=\"sortable stats_table now_sortable sticky_table eq1 eq2 re2 le1\")\n",
    "table2\n",
    "table_body = table.find('<tbody>')\n",
    "\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data1.append([ele for ele in cols if ele]) # Get rid of empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Trying to grab totals from last row of Scoring Plays Table\n",
    "#start with first game to get a sense of basic structure\n",
    "#response = requests.get(url_list[0])\n",
    "#page = response.text\n",
    "#soup = BeautifulSoup(page, 'html.parser')\n",
    "#Basic form to scrape any table\n",
    "#data = []\n",
    "#table = soup.find('table', attrs={'id':'scoring'})\n",
    "#table_body = table.find('tbody')\n",
    "\n",
    "#rows = table_body.find_all('tr')\n",
    "#for row in rows:\n",
    " #   cols = row.find_all('td')\n",
    " #   cols = [ele.text.strip() for ele in cols]\n",
    " #   data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "#rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting to use Comment module from bs4 package (didn't work; claimed Comment wasn't defined??)\n",
    "#to_remove = soup.find_all(text=Comment) \n",
    "#for element in to_remove: \n",
    "#    element.extract()\n",
    "\n",
    "#for comments in soup.findAll(text=lambda text:isinstance(text, Comment)):\n",
    "#    print(comments)\n",
    "#    comments.extract()\n",
    "\n",
    "#comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "#for c in comments:\n",
    "#    print(c)\n",
    "#    print(\"===========\")\n",
    "#    c.extract()\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
